{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the librarys\n",
    "import pandas as pd #To work with dataset\n",
    "import numpy as np #Math library\n",
    "import seaborn as sns #Graph library that use matplot in background\n",
    "import matplotlib.pyplot as plt #to plot some parameters in seaborn\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Import StandardScaler from scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Import train_test_split()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime, date\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as lgbm\n",
    "import  tensorflow as tf \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import smogn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "#import smong \n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read spreadsheet and assign it to swiss_loan\n",
    "swiss_loan= pd.read_excel('C:/Users/rzouga/Desktop/ALLINHERE/Assignement/ATUCE_Case_study_data_2021.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Pipeline (preprocessing ,cleaning , features eng, features selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask on whether each feature less than 40% missing values.\n",
    "mask = swiss_loan.isna().sum() / len(swiss_loan) < 0.4\n",
    "# Create a reduced dataset by applying the mask\n",
    "reduced_df =swiss_loan.loc[:, mask]\n",
    "\n",
    "# drop ID\n",
    "reduced_df.drop('ID', axis=1, inplace=True)\n",
    "reduced_df['Pays_corr']=reduced_df['Pays'].str.strip()\n",
    "reduced_df['Taux_corr']=reduced_df['Taux'].str.replace('%','').str.strip().str.replace(',','.').str.extract(r'(\\d+.\\d+)')\n",
    "reduced_df['Taux_corr'] = np.where(reduced_df['Taux_corr'].isnull(), 0.1, reduced_df['Taux_corr'])\n",
    "reduced_df['Taux_corr'] = pd.to_numeric(reduced_df['Taux_corr'], errors='coerce')\n",
    "# Specify the boundaries of the bins\n",
    "bins = [0.001,5.5,  6.5, 10]\n",
    "# Bin labels\n",
    "labels = [ 'Low', 'Medium', 'High']\n",
    "# Bin the continuous variable ConvertedSalary using these boundaries\n",
    "reduced_df['Taux_corr_binned'] = pd.cut(reduced_df['Taux_corr'], \n",
    "                                         bins=bins,labels=labels )\n",
    "# Print the first 5 rows of the boundary_binned column\n",
    "reduced_df['Montant_corr']=reduced_df['Montant'].str.replace('‚Ç¨','').str.replace('\\xa0','').str.strip().str.replace('\\s+','')\n",
    "reduced_df['Montant_corr'] = np.where(reduced_df['Montant_corr'].isnull(), 0.1, reduced_df['Montant_corr'])\n",
    "reduced_df['Montant_corr'] = pd.to_numeric(reduced_df['Montant_corr'], errors='coerce')\n",
    "reduced_df['Niveau_risque_corr']=reduced_df['Niveau de risque'].str.rstrip().str.replace('\\s+','')\n",
    "Emprunteurs = reduced_df['Emprunteur']\n",
    "\n",
    "\n",
    "Emprunteurs_counts = Emprunteurs.value_counts()\n",
    "\n",
    "# Create a mask for only categories that occur less than 5 times\n",
    "mask = Emprunteurs.isin(Emprunteurs_counts[Emprunteurs_counts<5].index)\n",
    "# Label all other categories as Other\n",
    "reduced_df['Emprunteur'][mask] = 'Other'\n",
    "reduced_df['capital_social_corr']=reduced_df['capital social'].str.replace('‚Ç¨','').str.replace('\\xa0','').str.strip().str.replace('\\s+','')\n",
    "reduced_df['capital_social_corr'] = np.where(reduced_df['capital_social_corr'].isnull(), 0.1, reduced_df['capital_social_corr'])\n",
    "reduced_df['capital_social_corr'] = pd.to_numeric(reduced_df['capital_social_corr'], errors='coerce')\n",
    "\n",
    "reduced_df['Effectifse_corr']=reduced_df['effectifs'].str.rstrip().str.replace('\\s+','')\n",
    "reduced_df['Effectifse_corr'][reduced_df['Effectifse_corr'] == '-'] = np.nan\n",
    "\n",
    "reduced_df['Nombre_mois_p√©riode16_corr']=reduced_df['Nombre de mois de la p√©riode 16'].str.rstrip().str.replace('mois','').str.replace(',','.').str.replace('\\s+','').str.extract(r\"(\\d+\\.\\d+|\\d+)\")\n",
    "reduced_df['Nombre_mois_p√©riode16_corr'][reduced_df['Nombre_mois_p√©riode16_corr'] == '-'] = np.nan\n",
    "reduced_df['Nombre_mois_p√©riode16_corr'] = pd.to_numeric(reduced_df['Nombre_mois_p√©riode16_corr'], errors='coerce')\n",
    "\n",
    "reduced_df['Chiffre_Affaires_16_corr']=reduced_df.iloc[:,12].str.replace('\\xa0','').str.strip().str.replace('\\s+','')\n",
    "reduced_df['Chiffre_Affaires_16_corr'] = pd.to_numeric(reduced_df['Chiffre_Affaires_16_corr'], errors='coerce')\n",
    "\n",
    "reduced_df['Total_Bilan_16_corr']= reduced_df['Total Bilan 16'].str.replace('\\xa0','').str.strip().str.replace('\\s+','').str.extract(r\"([-+]?\\d*\\.*\\d+|\\d+)\")\n",
    "reduced_df['Total_Bilan_16_corr']= pd.to_numeric(reduced_df['Total_Bilan_16_corr'], errors='coerce')\n",
    "\n",
    "reduced_df['Capacit√©_remboursement_FCCR_16_corr']= reduced_df['Capacit√© de remboursement (FCCR) 16'].str.replace('\\xa0','').str.strip().str.replace('\\s+','').str.replace(',','.').str.extract(r\"([-+]?\\d*\\.*\\d+|\\d+)\")\n",
    "reduced_df['Capacit√©_remboursement_FCCR_16_corr']= pd.to_numeric(reduced_df['Capacit√©_remboursement_FCCR_16_corr'], errors='coerce')\n",
    "\n",
    "\n",
    "reduced_df['Fonds_Propres_16_corr']= reduced_df['Fonds Propres 16'].str.replace('\\xa0','').str.strip().str.replace('\\s+','').str.replace(',','.').str.extract(r\"([-+]?\\d*\\.*\\d+|\\d+)\")\n",
    "reduced_df['Fonds_Propres_16_corr']= pd.to_numeric(reduced_df['Fonds_Propres_16_corr'], errors='coerce')\n",
    "\n",
    "reduced_df['Fonds_Propres_Total_Bilan_corr']= reduced_df['Fonds Propres / Total Bilan 16'].str.replace('\\xa0','').str.strip().str.replace('\\s+','').str.replace(',','.').str.replace('%','').str.extract(r\"([-+]?\\d*\\.*\\d+|\\d+)\")\n",
    "reduced_df['Fonds_Propres_Total_Bilan_corr']= pd.to_numeric(reduced_df['Fonds_Propres_Total_Bilan_corr'], errors='coerce')\n",
    "\n",
    "reduced_df['Dettes_Nettes_EBE_16_corr']= reduced_df['Dettes Nettes / EBE(* ann√©es) 16'].str.replace('\\xa0','').str.strip().str.replace('\\s+','').str.replace(',','.').str.replace('*','').str.extract(r\"([-+]?\\d*\\.*\\d+|\\d+)\")\n",
    "reduced_df['Dettes_Nettes_EBE_16_corr']= pd.to_numeric(reduced_df['Dettes_Nettes_EBE_16_corr'], errors='coerce')\n",
    "\n",
    "reduced_df['DettesNettes_Fonds_propres_16_corr']= reduced_df['Dettes Nettes / Fonds propres 16'].str.replace('\\xa0','').str.strip().str.replace('\\s+','').str.replace(',','.').str.replace('%','').str.extract(r\"([-+]?\\d*\\.*\\d+|\\d+)\")\n",
    "reduced_df['DettesNettes_Fonds_propres_16_corr']= pd.to_numeric(reduced_df['DettesNettes_Fonds_propres_16_corr'], errors='coerce')\n",
    "\n",
    "\n",
    "# Apply the log normalization function \n",
    "reduced_df['Montant_corr_log'] = np.log(reduced_df['Montant_corr'])\n",
    "\n",
    "# Apply the log normalization function \n",
    "reduced_df['Chiffre_Affaires_16_corr_log'] = np.log(reduced_df['Chiffre_Affaires_16_corr'])\n",
    "# Apply the log normalization function t\n",
    "reduced_df['capital_social_corr_log'] = np.log(reduced_df['capital_social_corr']+1)\n",
    "# This function converts given date to age\n",
    "def age(creation):\n",
    "    born = int(creation)\n",
    "    today = date.today()\n",
    "    return today.year - born\n",
    "  \n",
    "reduced_df['Age'] = reduced_df['ann√©e de cr√©ation'].apply(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688, 39)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Clean Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pays', 'Taux', 'Mois', 'Montant', 'Niveau de risque', 'Emprunteur',\n",
       "       'capital social', 'ann√©e de cr√©ation', 'Ant√©riorit√©', 'effectifs',\n",
       "       'Nombre de mois de la p√©riode 16', 'Chiffre d'Affaires 16',\n",
       "       'EBE(retrait√© des loyers de leasing) 16', 'Resultat Net 16',\n",
       "       'Total Bilan 16', 'Capacit√© de remboursement (FCCR) 16',\n",
       "       'Fonds Propres 16', 'Fonds Propres / Total Bilan 16',\n",
       "       'Dettes Nettes / EBE(* ann√©es) 16', 'Dettes Nettes / Fonds propres 16',\n",
       "       'Pays_corr', 'Taux_corr', 'Taux_corr_binned', 'Montant_corr',\n",
       "       'Niveau_risque_corr', 'capital_social_corr', 'Effectifse_corr',\n",
       "       'Nombre_mois_p√©riode16_corr', 'Chiffre_Affaires_16_corr',\n",
       "       'Total_Bilan_16_corr', 'Capacit√©_remboursement_FCCR_16_corr',\n",
       "       'Fonds_Propres_16_corr', 'Fonds_Propres_Total_Bilan_corr',\n",
       "       'Dettes_Nettes_EBE_16_corr', 'DettesNettes_Fonds_propres_16_corr',\n",
       "       'Montant_corr_log', 'Chiffre_Affaires_16_corr_log',\n",
       "       'capital_social_corr_log', 'Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688, 18)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_to_keep= [ 'Pays_corr','Mois','Age' ,'Taux_corr', 'Taux_corr_binned', 'Montant_corr_log',\n",
    "       'Niveau_risque_corr','Emprunteur', 'capital_social_corr_log', 'Effectifse_corr',\n",
    "       'Nombre_mois_p√©riode16_corr', 'Capacit√©_remboursement_FCCR_16_corr','Total_Bilan_16_corr',\n",
    "       'Fonds_Propres_16_corr', 'Fonds_Propres_Total_Bilan_corr',\n",
    "       'Dettes_Nettes_EBE_16_corr', 'DettesNettes_Fonds_propres_16_corr','Chiffre_Affaires_16_corr_log']\n",
    "clean_reduced_df= reduced_df[list_to_keep].copy()\n",
    "clean_reduced_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 : REGRESSION : predict \"Taux_corr\"\n",
    "## Extract X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 rows in test set vs. 619 in training set. 16 Features.\n"
     ]
    }
   ],
   "source": [
    "# Create arrays for the features and the response variable\n",
    "colonne_cible = \"Taux_corr\"\n",
    "\n",
    "Data_regression =clean_reduced_df.drop(['Taux_corr_binned'], axis=1).copy()\n",
    "X = Data_regression.drop(['Taux_corr'], axis=1)\n",
    "y= Data_regression['Taux_corr']\n",
    "# Split the dataset and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "print(\"{} rows in test set vs. {} in training set. {} Features.\".format(X_test.shape[0], X_train.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What should we do for each colmun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the float columns\n",
    "num_columns = X.select_dtypes(include=['int64','float64']).columns\n",
    "# select non-numeric columns\n",
    "cat_columns = X.select_dtypes(exclude=['int64','float64']).columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check that we have all column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "num_columns=['Mois', 'Age', 'Montant_corr_log', 'capital_social_corr_log',\n",
    "       'Nombre_mois_p√©riode16_corr', 'Capacit√©_remboursement_FCCR_16_corr',\n",
    "       'Fonds_Propres_16_corr', 'Fonds_Propres_Total_Bilan_corr',\n",
    "       'Dettes_Nettes_EBE_16_corr', 'DettesNettes_Fonds_propres_16_corr',\n",
    "       'Chiffre_Affaires_16_corr_log']\n",
    "cat_columns=['Pays_corr', 'Niveau_risque_corr', 'Emprunteur',\n",
    "       'Effectifse_corr']\n",
    "all_columns = (num_columns\n",
    "               +cat_columns)\n",
    "\n",
    "if set(all_columns) == set(X1.columns):\n",
    "    print('Ok')\n",
    "else:\n",
    "    # Alors je veux voir les diff√©rences\n",
    "    print('dans all_columns mais pas dans X1.columns   :', set(all_columns) - set(X1.columns))\n",
    "    print('dans X.columns   mais pas dans all_columns :', set(X1.columns) - set(all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'==>i have just create Taux_corr_binned in  order to do a classifcation task '"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"==>i have just create Taux_corr_binned in  order to do a classifcation task \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create complexe transformer  in order to  put all transformations in the same pipe \n",
    "In our case :\n",
    "\n",
    "    'num_columns' :Cleaning->Valeur Manquante -> Standar_Scaler\n",
    "    'cat_columns' : Cleaning -> Valeur Manquante -> Categorique [One Hot]\n",
    "**==> Cleaning is done by pandas , in the future this step sould be intergeted the pipe using \"custumer Function\" like this Example:**\n",
    "\n",
    "    fill_missing_then_Standar_scaler = make_pipeline( SimpleImputer(strategy='median',add_indicator=True),\n",
    "        StandardScaler()\n",
    "    )\n",
    "\n",
    "    \"Write a pattern to extract numbers and decimals\"\n",
    "    def return_number(string):\n",
    "        pattern = re.compile(r\"\\d+\\.\\d+\")\n",
    "        # Search the text for matches\n",
    "        number = re.match(pattern, string)\n",
    "        # If a value is returned, use group(0) to return the found value\n",
    "        if number is not None:\n",
    "            return float(number.group(0))\n",
    "\n",
    "    extraire_number_then_imput_then_scale = make_pipeline(\n",
    "        FunctionTransformer(extract_number),\n",
    "        fill_missing_then_Standar_scaler,\n",
    "    )    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipe Cat columns : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missing_then_one_hot_encoder = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='manquante',add_indicator=True),\n",
    "    OneHotEncoder(handle_unknown='ignore')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipe Numeric Columns : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    " fill_missing_then_StandardScaler = make_pipeline( SimpleImputer(strategy='median',add_indicator=True),\n",
    "    StandardScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compose num+cat : ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocess = make_column_transformer(\n",
    "    ( fill_missing_then_one_hot_encoder , cat_columns),\n",
    "    ( fill_missing_then_StandardScaler, num_columns)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok , Every thing is well \n"
     ]
    }
   ],
   "source": [
    "data_preprocess.fit(X)\n",
    "data_preprocess.transform(X)\n",
    "data_preprocess.transform(X_test)\n",
    "\n",
    "print(\"Ok , Every thing is well \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Pipe\n",
    "## Step 1: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=77, shuffle=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation_design = KFold(n_splits=5,\n",
    "                                shuffle=True,\n",
    "                                random_state=77)\n",
    "\n",
    "cross_validation_design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=77, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('data_process',\n",
       "                                        ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(add_indicator=True,\n",
       "                                                                                                        fill_value='manquante',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('onehotencoder',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['Pays_corr',\n",
       "                                                                          'Niveau_risque_c...\n",
       "                                                                          'Fonds_Propres_16_corr',\n",
       "                                                                          'Fonds_Propres_Total_Bilan_corr',\n",
       "                                                                          'Dettes_Nettes_EBE_16_corr',\n",
       "                                                                          'DettesNettes_Fonds_propres_16_corr',\n",
       "                                                                          'Chiffre_Affaires_16_corr_log'])])),\n",
       "                                       ('knn', KNeighborsRegressor())]),\n",
       "             param_grid={'knn__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
       "                         'knn__n_neighbors': [1, 3, 5, 8, 9, 10, 11, 15, 20, 21,\n",
       "                                              51],\n",
       "                         'knn__weights': ['uniform', 'distance']},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "\n",
    "# params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "\n",
    "\n",
    "KNN_MODEL = {}\n",
    "\n",
    "# D√©finir la pipeline\n",
    "KNN_MODEL['pipeline'] = Pipeline([\n",
    "                                  ('data_process', data_preprocess),\n",
    "                                  ('knn', KNN())\n",
    "                                  ])\n",
    "\n",
    "# D√©finir la grille\n",
    "KNN_MODEL['hyperparams'] = {}\n",
    "KNN_MODEL['hyperparams']['knn__n_neighbors'] = [1, 3,5,8, 9,10,11,15, 20,21, 51]\n",
    "KNN_MODEL['hyperparams']['knn__weights'] = ['uniform','distance']\n",
    "KNN_MODEL['hyperparams']['knn__metric'] = ['euclidean', 'manhattan', 'minkowski']\n",
    "\n",
    "# Effectuer la GridSearch\n",
    "KNN_MODEL['gridsearch'] = GridSearchCV(\n",
    "    estimator=KNN_MODEL['pipeline'],\n",
    "    param_grid=KNN_MODEL['hyperparams'],\n",
    "    cv=cross_validation_design,\n",
    "    scoring='r2'\n",
    "    )\n",
    "\n",
    "KNN_MODEL['gridsearch'].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__metric': 'manhattan',\n",
       " 'knn__n_neighbors': 51,\n",
       " 'knn__weights': 'distance'}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_MODEL['gridsearch'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07611574307552002"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_MODEL['gridsearch'].best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=77, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('data_cleaning',\n",
       "                                        ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(add_indicator=True,\n",
       "                                                                                                        fill_value='manquante',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('onehotencoder',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['Pays_corr',\n",
       "                                                                          'Niveau_risque_...\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['Mois',\n",
       "                                                                          'Age',\n",
       "                                                                          'Montant_corr_log',\n",
       "                                                                          'capital_social_corr_log',\n",
       "                                                                          'Nombre_mois_p√©riode16_corr',\n",
       "                                                                          'Capacit√©_remboursement_FCCR_16_corr',\n",
       "                                                                          'Fonds_Propres_16_corr',\n",
       "                                                                          'Fonds_Propres_Total_Bilan_corr',\n",
       "                                                                          'Dettes_Nettes_EBE_16_corr',\n",
       "                                                                          'DettesNettes_Fonds_propres_16_corr',\n",
       "                                                                          'Chiffre_Affaires_16_corr_log'])])),\n",
       "                                       ('reg', LinearRegression())]),\n",
       "             param_grid={}, scoring='r2')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# D√©finir la pipeline\n",
    "REGRESSION_MODEL = {}\n",
    "REGRESSION_MODEL['pipeline'] = Pipeline([\n",
    "                                        ('data_cleaning', data_preprocess ),\n",
    "                                        ('reg', LinearRegression())\n",
    "])\n",
    "\n",
    "# D√©finir la grille\n",
    "REGRESSION_MODEL['hyperparams'] = {}\n",
    "#REGRESSION_MODEL['hyperparams']['reg__alpha'] = np.arange(.1, 10., .1)\n",
    "\n",
    "# Faire la recherche\n",
    "REGRESSION_MODEL['gridsearch'] = GridSearchCV(\n",
    "                                      estimator=REGRESSION_MODEL['pipeline'],\n",
    "                                      param_grid=REGRESSION_MODEL['hyperparams'],\n",
    "                                      cv=cross_validation_design,\n",
    "                                      scoring='r2'\n",
    "                                      )\n",
    "\n",
    "REGRESSION_MODEL['gridsearch'].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### you can obtain the coefficient of determination (ùëÖ¬≤) with .score() called on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.11939354183583073\n"
     ]
    }
   ],
   "source": [
    "model = REGRESSION_MODEL['gridsearch'].fit(X_train, y_train)\n",
    "r_sq = model.score(X_train, y_train)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "df_LR = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df_LR.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 3.011946114911504\n",
      "Mean Squared Error: 31.908159717606434\n",
      "Root Mean Squared Error: 5.648730805907326\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.733354517544875"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REGRESSION_MODEL['gridsearch'].best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.11830695095531307\n"
     ]
    }
   ],
   "source": [
    "# instantiate linear regression object\n",
    "ridge = RidgeCV()\n",
    "ridge_MODEL = Pipeline([\n",
    "                                        ('data_cleaning', data_preprocess ),\n",
    "                                        ('reg', ridge)\n",
    "])\n",
    "# fit or train the linear regression model on the training set and store parameters\n",
    "ridge_MODEL.fit(X_train, y_train)\n",
    "\n",
    "r_sq = ridge_MODEL.score(X_train, y_train)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training data:  2.827170972169815\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>5.35</td>\n",
       "      <td>4.850579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.50</td>\n",
       "      <td>4.085489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>7.25</td>\n",
       "      <td>4.909013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.75</td>\n",
       "      <td>5.296130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>7.50</td>\n",
       "      <td>4.049366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "439    5.35   4.850579\n",
       "90     5.50   4.085489\n",
       "315    7.25   4.909013\n",
       "5      6.75   5.296130\n",
       "678    7.50   4.049366"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use trained RidgeCV regression model to predict interest rates of training and test data\n",
    "\n",
    "y_pred = ridge_MODEL.predict(X_test)\n",
    "df_Ridge = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# print RMSE of training predictions\n",
    "print('RMSE on training data: ', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "df_Ridge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR pipe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Accuracy :  -0.14699522888219851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor = SVR()\n",
    "SVR_MODEL = {}\n",
    "\n",
    "# D√©finir la pipeline\n",
    "SVR_MODEL['pipeline'] = Pipeline([\n",
    "                                  ('data_process', data_preprocess),\n",
    "                                  ('SVR', regressor)\n",
    "                                  ])\n",
    "\n",
    "# D√©finir la grille\n",
    "SVR_MODEL['hyperparams'] = {}\n",
    "SVR_MODEL['hyperparams']['SVR__kernel'] = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "SVR_MODEL['hyperparams']['SVR__degree'] = [0,1,2, 3, 4,5,6,7,8,9]\n",
    "SVR_MODEL['hyperparams']['SVR__gamma'] = ['scale', 'auto',1, 0.1, 0.01, 0.001, 0.0001]\n",
    "SVR_MODEL['hyperparams']['SVR__C'] = [50, 10, 1.0, 0.1, 0.01,100]\n",
    "\n",
    "# Effectuer la GridSearch\n",
    "SVR_MODEL['gridsearch'] = GridSearchCV(\n",
    "    estimator=SVR_MODEL['pipeline'],\n",
    "    param_grid=SVR_MODEL['hyperparams'],\n",
    "    cv=cross_validation_design,\n",
    "    scoring='r2'\n",
    "    )\n",
    "\n",
    "#Define SVR classifier\n",
    "SVR_MODEL['gridsearch'].fit(X_train, y_train)\n",
    "svr_accuracy = SVR_MODEL['gridsearch'].score(X_test, y_test)\n",
    "\n",
    "print('Support Vector Classifier Accuracy : ', svr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'cache_size', 'coef0', 'degree', 'epsilon', 'gamma', 'kernel', 'max_iter', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVR__C': 10, 'SVR__degree': 0, 'SVR__gamma': 1, 'SVR__kernel': 'rbf'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVR_MODEL['gridsearch'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"{'SVR__C': 10, 'SVR__degree': 0, 'SVR__gamma': 1, 'SVR__kernel': 'rbf'}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XGBOOST Regressor  pipe :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:29:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:29:49] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:29:49] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:29:49] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:29:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:29:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "SXGBR Accuracy :  -0.05835190821407488\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "XGBR = XGBRegressor()\n",
    "XGBR_MODEL = {}\n",
    "# D√©finir la pipeline\n",
    "XGBR_MODEL['pipeline'] = Pipeline([\n",
    "                                  ('data_process', data_preprocess),\n",
    "                                  ('XGBR', XGBR)\n",
    "                                  ])\n",
    "\n",
    "# D√©finir la grille\n",
    "XGBR_MODEL['hyperparams'] = {}\n",
    "#XGBR_MODEL['hyperparams']['XGBR__n_estimators'] = [10,20]\n",
    "#XGBR_MODEL['hyperparams']['XGBR__colsample_bytree'] = [0.7, 0.8]\n",
    "#XGBR_MODEL['hyperparams']['XGBR__max_depth'] = [5,7,15]\n",
    "#XGBR_MODEL['hyperparams']['XGBR__reg_alpha'] = [1.1, 1.2 ]\n",
    "#XGBR_MODEL['hyperparams']['XGBR__reg_lambda'] = [1.1, 1.2, 1.3]\n",
    "#XGBR_MODEL['hyperparams']['XGBR__subsample'] = [0.7, 0.8, 0.9]\n",
    "# Effectuer la GridSearch\n",
    "XGBR_MODEL['gridsearch'] = GridSearchCV(\n",
    "    estimator=XGBR_MODEL['pipeline'],\n",
    "    param_grid=XGBR_MODEL['hyperparams'],\n",
    "    cv=cross_validation_design,\n",
    "    scoring='r2'\n",
    "    )\n",
    "#Define SVR classifier\n",
    "XGBR_MODEL['gridsearch'].fit(X_train, y_train)\n",
    "XGBR_accuracy = XGBR_MODEL['gridsearch'].score(X_test, y_test)\n",
    "print('SXGBR Accuracy : ', XGBR_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBR__colsample_bytree': 0.7,\n",
       " 'XGBR__max_depth': 5,\n",
       " 'XGBR__n_estimators': 20,\n",
       " 'XGBR__reg_alpha': 1.2,\n",
       " 'XGBR__reg_lambda': 1.2,\n",
       " 'XGBR__subsample': 0.7}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBR_MODEL['gridsearch'].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Stacking\n",
    "Improve your Predictive Model‚Äôs Score using a Stacking Regressor\n",
    "\n",
    "      ‚ÄúThe whole is greater than the sum of its parts.‚Äù ‚Äì Aristotle\n",
    "## Type 1: Simplest Stacking Regressor approach: Averaging Base models\n",
    "\n",
    "We begin with this simple approach of averaging base models. Build a new class to extend scikit-learn with our model and also to leverage encapsulation and code reuse.\n",
    "\n",
    "### Averaged base models class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      " Averaged RMSE base models score: 3.2030\n",
      " Averaged R2 base models score: nan\n"
     ]
    }
   ],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)\n",
    "ENet = ElasticNet()\n",
    "lasso = Lasso()  \n",
    "KRR = KernelRidge()\n",
    "GBoost = GradientBoostingRegressor()\n",
    "model_xgb = xgb.XGBRegressor()\n",
    "model_lgb = lgb.LGBMRegressor()\n",
    "averaged_models = AveragingModels(models = (ENet,model_lgb,model_xgb, GBoost, KRR, lasso))\n",
    "averaged_models_pipe = Pipeline([('data_cleaning', data_preprocess),\n",
    "                        ('Stack_reg1', averaged_models)\n",
    "                        ])\n",
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(averaged_models_pipe,X_train, y_train, scoring=\"neg_mean_squared_error\", cv = cross_validation_design))\n",
    "    return(rmse)\n",
    "def r2_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(averaged_models_pipe,X_train, y_train, scoring=\"r2\", cv = cross_validation_design))\n",
    "    return(rmse)\n",
    "score = rmse_cv(averaged_models)\n",
    "r2_score = r2_cv(averaged_models)\n",
    "print(\" Averaged RMSE base models score: {:.4f}\".format(score.mean()))\n",
    "print(\" Averaged R2 base models score: {:.4f}\".format(r2_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type 2: Adding a Meta-model\n",
    "The meta-model is used to find the pattern between the base model predictions as features and actual predictions as the target variables.\n",
    "## First Stacking Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:24:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:24:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:24:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:24:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:24:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean Squared Error: 7.4952\n",
      "Variance Score: -0.0116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "\n",
    "estimators = [('Ridge', RidgeCV()),\n",
    "    ('svr', LinearSVR(random_state=42)) ,\n",
    "    ('XGBR',XGBRegressor()),\n",
    "    ('KNN',KNeighborsRegressor())]\n",
    "     \n",
    "Stack_reg1 = StackingRegressor(estimators=estimators,final_estimator=RandomForestRegressor(n_estimators=10, random_state=42))\n",
    "Stack_reg1_pipe = Pipeline([('data_cleaning', data_preprocess),\n",
    "                        ('Stack_reg1', Stack_reg1)\n",
    "                        ])\n",
    "\n",
    "Stack_reg1_pipe.fit(X_train, y_train)    \n",
    "print(\"Mean Squared Error: %.4f\"% np.mean((Stack_reg1_pipe.predict(X_test) - y_test) ** 2))\n",
    "print('Variance Score: %.4f' % Stack_reg1_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Stacking Model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 9.7030\n",
      "Variance Score: -0.3096\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "from mlxtend.data import boston_housing_data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "# Initializing models\n",
    "\n",
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "Stack_reg2= StackingRegressor(regressors=[svr_lin, lr, ridge], \n",
    "                           meta_regressor=svr_rbf)\n",
    "\n",
    "# Training the stacking classifier\n",
    "\n",
    "Stack_reg2_pipe = Pipeline([('data_cleaning', data_preprocess),\n",
    "                        ('Stack_reg2', Stack_reg2)\n",
    "                        ])\n",
    "\n",
    "Stack_reg2_pipe.fit(X_train, y_train)    \n",
    "print(\"Mean Squared Error: %.4f\"% np.mean((Stack_reg2_pipe.predict(X_test) - y_test) ** 2))\n",
    "print('Variance Score: %.4f' % Stack_reg2_pipe.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Third Stacking Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 9.7083\n",
      "Variance Score in test : -0.3103\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Initializing models\n",
    "\n",
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "lasso = Lasso(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "regressors = [svr_lin, lr, ridge, lasso]\n",
    "stregr3 = StackingRegressor(regressors=regressors, \n",
    "                           meta_regressor=svr_rbf)\n",
    "\n",
    "\n",
    "#params = {'lasso__alpha': [0.1, 1.0, 10.0],\n",
    "          #'ridge__alpha': [0.1, 1.0, 10.0],\n",
    "          #'svr__C': [0.1, 1.0, 10.0],\n",
    "          #'meta_regressor__C': [0.1, 1.0, 10.0, 100.0],\n",
    "          #'meta_regressor__gamma': [0.1, 1.0, 10.0]}\n",
    "\n",
    "Stack_reg3_pipe = Pipeline([('data_cleaning', data_preprocess),\n",
    "                        ('Stack_reg3', stregr3)\n",
    "                        ])\n",
    "\n",
    "#grid_reg3_pipe = GridSearchCV(estimator=Stack_reg3_pipe, param_grid=params, cv=cross_validation_design, refit=True)\n",
    "\n",
    "Stack_reg3_pipe.fit(X_train, y_train)    \n",
    "print(\"Mean Squared Error: %.4f\"% np.mean((Stack_reg3_pipe.predict(X_test) - y_test) ** 2))\n",
    "print('Variance Score in test : %.4f' % Stack_reg3_pipe.score(X_test, y_test))\n",
    "\n",
    "#print(\"Best score o, training : %f using %s\" % (grid_reg3_pipe.best_score_, grid_reg3_pipe.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Approch :\n",
    "## Step Model Life-Cycle\n",
    "A model has a life-cycle,modeling a dataset and understanding the tf.keras API.\n",
    "The five steps in the life-cycle are as follows:\n",
    "   - Define the model.\n",
    "   - Compile the model.\n",
    "   - Fit the model.\n",
    "   - Evaluate the model.\n",
    "   - Make predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 30)                1290      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,131\n",
      "Trainable params: 2,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model1 = tf.keras.Sequential()\n",
    "    model1.add( layers.Dense(30, activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "                             input_shape=[X_pre.shape[1]]))\n",
    "    model1.add(layers.Dropout(0.2))\n",
    "    model1.add(layers.Dense(20, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    model1.add(layers.Dropout(0.2))\n",
    "    model1.add(layers.Dense(10, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    model1.add(layers.Dropout(0.1))\n",
    "    model1.add(layers.Dense(1,activation='relu'))  \n",
    "    #optimizer='adam'\n",
    "    optimizer =tf.keras.optimizers.Adam()\n",
    "    #optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "     ## Compile model\n",
    "    #epochs = 50\n",
    "    #learning_rate = 0.1\n",
    "    #decay_rate = learning_rate / epochs\n",
    "    #momentum = 0.8\n",
    "    #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    #https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/\n",
    "    #optimizer=sgd\n",
    "    model1.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "    return model1\n",
    "\n",
    "MLP = build_model()\n",
    "MLP.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS =1000\n",
    "# configure early stopping\n",
    "es = EarlyStopping(monitor='val_loss',min_delta=0.0000000000001, patience=5)\n",
    "#batch_size=1000\n",
    "#MLP_pipe = Pipeline([('data_cleaning', data_preprocess),('MLP', MLP)])\n",
    "X = Data_regression.drop(['Taux_corr'], axis=1)\n",
    "y_pre= Data_regression['Taux_corr'].to_numpy()\n",
    "X_pre=data_preprocess.fit_transform(X)\n",
    "history = MLP.fit(X_pre,y_pre,batch_size=32,epochs=EPOCHS, validation_split = 0.1, verbose=0 ,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.save('my_modelMLP.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let‚Äôs see what this looks like when we plot our respective losses:\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - loss: 8.3356 - mae: 2.2938 - mse: 7.0800\n",
      " Mean Abs Error:  7.08 MPG\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "loss, mae, mse = MLP.evaluate( X_pre, y_pre, verbose=2)\n",
    "print(\" Mean Abs Error: {:5.2f} MPG\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model Selection\n",
    "\n",
    "In machine learning, we usually select our final model after evaluating several candidate models. This process is called model selection. Sometimes the models subject to comparison are fundamentally different in nature (say, decision trees vs. linear models). At other times, we are comparing members of the same class of models that have been trained with different hyperparameter settings.\n",
    "\n",
    "With MLPs, for example, we may wish to compare models with different numbers of hidden layers, different numbers of hidden units, and various choices of the activation functions applied to each hidden layer. In order to determine the best among our candidate models, we will typically employ a validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the best model : retrain on all the data(without cross_val)with the best param \n",
    "\n",
    " This pipline will be used in production "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('data_cleaning',\n",
       "                 ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 fill_value='manquante',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehotencoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Pays_corr',\n",
       "                                                   'Niveau_risque_corr',\n",
       "                                                   'Emprunteur',\n",
       "                                                   'Effectifse_corr']),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('si...\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Mois', 'Age',\n",
       "                                                   'Montant_corr_log',\n",
       "                                                   'capital_social_corr_log',\n",
       "                                                   'Nombre_mois_p√©riode16_corr',\n",
       "                                                   'Capacit√©_remboursement_FCCR_16_corr',\n",
       "                                                   'Fonds_Propres_16_corr',\n",
       "                                                   'Fonds_Propres_Total_Bilan_corr',\n",
       "                                                   'Dettes_Nettes_EBE_16_corr',\n",
       "                                                   'DettesNettes_Fonds_propres_16_corr',\n",
       "                                                   'Chiffre_Affaires_16_corr_log'])])),\n",
       "                ('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ])))])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocess = make_column_transformer(\n",
    "    ( fill_missing_then_one_hot_encoder , cat_columns),\n",
    "    ( fill_missing_then_StandardScaler, num_columns)\n",
    ")\n",
    "\n",
    "model_final = Pipeline([('data_cleaning', data_preprocess),\n",
    "                        ('ridge', ridge\n",
    "                        )])\n",
    "\n",
    "\n",
    "# on fit la meilleur pipe sur toute nos donn√©es de train\n",
    "model_final.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training data:  2.585471066714785\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>7.50</td>\n",
       "      <td>5.649141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>6.25</td>\n",
       "      <td>5.309654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.10</td>\n",
       "      <td>3.402927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>6.35</td>\n",
       "      <td>5.655560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>7.20</td>\n",
       "      <td>4.297518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "637    7.50   5.649141\n",
       "665    6.25   5.309654\n",
       "250    0.10   3.402927\n",
       "513    6.35   5.655560\n",
       "449    7.20   4.297518"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use trained RidgeCV regression model to predict interest rates of training and test data\n",
    "\n",
    "y_pred = model_final.predict(X_test)\n",
    "df_model_final = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# print RMSE of training predictions\n",
    "print('RMSE on training data: ', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "df_model_final.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum up :\n",
    "##  Dataset Size\n",
    "\n",
    "The other big consideration to bear in mind is the dataset size. Fixing our model, the fewer samples we have in the training dataset, the more likely (and more severely) we are to encounter overfitting. As we increase the amount of training data, the generalization error typically decreases. Moreover, in general, more data never hurt. For a fixed task and data distribution, there is typically a relationship between model complexity and dataset size. Given more data, we might profitably attempt to fit a more complex model. Absent sufficient data, simpler models may be more difficult to beat. For many tasks, deep learning only outperforms linear models when many thousands of training examples are available. \n",
    "# Underfitting \n",
    "\n",
    "Underfitting is a modeling error which occurs when a function does not fit the data points well enough. It is the result of a simple model with an insufficient number of training points. A model that is under fitted is inaccurate because the trend does not reflect the reality of the data.\n",
    "Handling Underfitting:\n",
    "\n",
    "    Get more training data.\n",
    "    Increase the size or number of parameters in the model.\n",
    "    Increase the complexity of the model.\n",
    "    Increasing the training time, until cost function is minimised.\n",
    "\n",
    "With these techniques, you should be able to improve your models and correct any overfitting or underfitting issues.\n",
    "# Prefer Confidence Intervals to Point Estimates with use of synthetic samples\n",
    "**Regression problem to a Classification problem**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
